{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_image_scraper_methods",
      "provenance": [],
      "authorship_tag": "ABX9TyMX8M/mt5Yz7Rq7fcLnhOlF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrodySpearman/Python-image-scraping-methods/blob/main/python_image_scraper_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQRjVAs2rU5f"
      },
      "source": [
        "# **Image scraper with Python**\n",
        "\n",
        "# ***Method one: BeautifulSoup with requests to collect html metadata.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRu_Lz8zrTlx"
      },
      "source": [
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install ipyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS6k-No4rk6Z"
      },
      "source": [
        "from bs4 import BeautifulSoup as soup\n",
        "import requests\n",
        "\n",
        "# parameters\n",
        "url = 'https://www.google.com/search?q=abstract+art&client=opera-gx&hs=rdy&sxsrf=ALeKk02DmSL4rU1lcwug_EMwN5Sodd4uHQ:1625774758469&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjo6dn3otTxAhV8Ap0JHVgLDMIQ_AUoAXoECAEQAw'\n",
        "\n",
        "def get_image_data(url):\n",
        "  r = requests.get(url)\n",
        "  return r.text\n",
        "\n",
        "htmldata = get_image_data(url)\n",
        "raw_images = soup(htmldata,'html.parser')\n",
        "\n",
        "for item in raw_images.find_all('img'):\n",
        "  print(item['src'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ATppcmExGOI"
      },
      "source": [
        "# Pros: \n",
        "\n",
        "\n",
        "*   Very readable\n",
        "*   Very simple\n",
        "*   Modular\n",
        "\n",
        "---\n",
        "\n",
        "# Cons:\n",
        "\n",
        "\n",
        "*   Can get messy quick.\n",
        "*   Can only draw off url, rather than key lookup searches. With webdriver however this functionality could be possible.\n",
        "*   Limited: can't scroll, problems when encountering infinite webpages.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySw0E7_Ixwk-"
      },
      "source": [
        "# ***Method Two: Selenium combined with Chrome webdriver.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ACNDobwx5f"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "import os\n",
        "from random import randint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Image\n",
        "import ipyplot\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLc0ie759XRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b5b3ec-30e7-476f-d9b0-cd8a206e8f56"
      },
      "source": [
        "# Parameters for scraping\n",
        "query = 'abstract'\n",
        "num_of_images = 50\n",
        "\n",
        "def get_images(query, num_of_images):\n",
        "\n",
        "  # Needed to work on a jupyter notebook, otherwise would just need to specify a local drive location.\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "  driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "  driver.get('https://www.google.com/imghp?hl=en&authuser=0&ogbl') # driver directed towards google images\n",
        "\n",
        "  # xpath to the html element corrosponding to search bar\n",
        "  box = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')\n",
        "  box.send_keys(query) # inputs query into search bar\n",
        "  box.send_keys(Keys.ENTER)\n",
        "\n",
        "  def auto_scroll():\n",
        "    scroll_height = 'return document.body.scrollHeight'\n",
        "    last_height = driver.execute_script(scroll_height)\n",
        "\n",
        "    while True:\n",
        "      driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
        "      time.sleep(2)\n",
        "      new_height = driver.execute_script(scroll_height) # Scrolls to bottom of page and resets scroll height\n",
        "      try:\n",
        "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
        "        time.sleep(2)\n",
        "      except:\n",
        "        pass\n",
        "      if new_height == last_height:\n",
        "        break\n",
        "      last_height = new_height\n",
        "\n",
        "  auto_scroll()\n",
        "\n",
        "  test_dir_name = f'test_{str(randint(10000,100000))}' \n",
        "  test_dir_path = f'/content/drive/My Drive/scrape_test/{test_dir_name}/'\n",
        "  test_folder = os.mkdir(test_dir_path) # creates a test directory to store data\n",
        "\n",
        "  print('finding images...')\n",
        "  for i in range(1, num_of_images):\n",
        "    image_name = f'testImage ({str(i)}).png'\n",
        "    image_path = f'/content/drive/My Drive/scrape_test/{test_dir_name}/{image_name}'\n",
        "    try:\n",
        "      image_location = driver.find_element_by_xpath(f'//*[@id=\"islrg\"]/div[1]/div[{str(i)}]/a[1]/div[1]/img')\n",
        "      image = image_location.screenshot(image_path)\n",
        "\n",
        "      \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  print('content downloaded!')\n",
        "\n",
        "get_images(query, num_of_images)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: use options instead of chrome_options\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finding images...\n",
            "content downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i5NR--Wb7uc"
      },
      "source": [
        "# Pros:\n",
        "\n",
        "*   Easy integration and downloads to google drive.\n",
        "*   Can download large amounts of images at a time, great for dataset building.\n",
        "*   Scalable.\n",
        "*   Specifying html data by xpath makes it easy to modify.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Cons:\n",
        "\n",
        "*   *Very* messy right now. Images are low resolution and many images contain other residual google elements and white spaces. \n",
        "*   A tad more complicated than method one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMi8NbpsjZG9"
      },
      "source": [
        "# ***Cropping white space out of uncleaned dataset***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A55k7FejnLA"
      },
      "source": [
        "# Our dataset is a little chaotic, due to the screenshot nature. We need to iterate through each image\n",
        "# in a dataset directory and clean it out by finding where the edges of images are and doing some cropping work.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}